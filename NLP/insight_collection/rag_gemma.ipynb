{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# RAG: Using Gemma LLM locally for question answering on private data","metadata":{}},{"cell_type":"markdown","source":"In this notebook, our aim is to develop a RAG system utilizing [Google's Gemma](https://ai.google.dev/gemma) model. We'll generate vectors with [Elastic's ELSER](https://www.elastic.co/guide/en/machine-learning/current/ml-nlp-elser.html) model and store them in Elasticsearch. Additionally, we'll explore semantic retrieval techniques and present the top search results as a context window to the Gemma model. Furthermore, we'll utilize the [Hugging Face transformer](https://huggingface.co/google/gemma-2b-it) library to load Gemma on a local environment.","metadata":{}},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"markdown","source":"**Elastic Credentials** - Create an [Elastic Cloud deployment](https://www.elastic.co/search-labs/tutorials/install-elasticsearch/elastic-cloud) to get all Elastic credentials (`ELASTIC_CLOUD_ID`,` ELASTIC_API_KEY`).\n\n**Hugging Face Token** - To get started with the [Gemma](https://huggingface.co/google/gemma-2b-it) model, it is necessary to agree to the terms on Hugging Face and generate the [access token](https://huggingface.co/docs/hub/en/security-tokens) with `write` role.\n\n**Gemma Model** - We're going to use [gemma-2b-it](https://huggingface.co/google/gemma-2b-it), though Google has released 4 open models. You can use any of them i.e. [gemma-2b](https://huggingface.co/google/gemma-2b), [gemma-7b](https://huggingface.co/google/gemma-7b), [gemma-7b-it](https://huggingface.co/google/gemma-7b-it)","metadata":{}},{"cell_type":"markdown","source":"## Install packages","metadata":{}},{"cell_type":"code","source":"pip install -q -U elasticsearch langchain transformers huggingface_hub ray","metadata":{"execution":{"iopub.status.busy":"2024-04-10T14:34:26.879207Z","iopub.execute_input":"2024-04-10T14:34:26.879971Z","iopub.status.idle":"2024-04-10T14:34:53.446104Z","shell.execute_reply.started":"2024-04-10T14:34:26.879938Z","shell.execute_reply":"2024-04-10T14:34:53.445021Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.8.2 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.4.0 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.1.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.2 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.4.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.1.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import packages","metadata":{}},{"cell_type":"code","source":"import json\nimport os\nfrom getpass import getpass\nfrom urllib.request import urlopen\nimport requests\nimport torch\nimport ray\nimport gc\n\nfrom elasticsearch import Elasticsearch, helpers\nfrom langchain.text_splitter import CharacterTextSplitter\nfrom langchain.vectorstores import ElasticsearchStore\nfrom langchain import HuggingFacePipeline\nfrom langchain.chains import RetrievalQA\nfrom langchain.prompts import ChatPromptTemplate\nfrom langchain.schema.output_parser import StrOutputParser\nfrom langchain.schema.runnable import RunnablePassthrough\nfrom huggingface_hub import login\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom transformers import AutoTokenizer, pipeline\nfrom torch.nn.parallel import DataParallel","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:22:25.915814Z","iopub.execute_input":"2024-04-10T16:22:25.916456Z","iopub.status.idle":"2024-04-10T16:22:25.923696Z","shell.execute_reply.started":"2024-04-10T16:22:25.916421Z","shell.execute_reply":"2024-04-10T16:22:25.922577Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"## Get Credentials","metadata":{}},{"cell_type":"code","source":"#ELASTIC_API_KEY = getpass(\"Elastic API Key :\")\nELASTIC_API_KEY = \"QmhaYXg0NEJTbzNMaVQ0eUVDY3U6V1QzMkZtcWVST3k5VlRCbWlqRFpQQQ==\"\n\n#ELASTIC_CLOUD_ID = getpass(\"Elastic Cloud ID :\")\nELASTIC_CLOUD_ID = \"RAG_G2:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvJGNiYWE5N2ZlMWQyYTQ3MTdhYjEzYTNlMmRkM2MyZmExJGVjMWM4MWI2NWRiNjQ5YjRiNDlkOTEyOTdiYzU3YTk2\"\n\nelastic_index_name = \"gemma-rag\"","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:20:26.610239Z","iopub.execute_input":"2024-04-10T16:20:26.611411Z","iopub.status.idle":"2024-04-10T16:20:26.615542Z","shell.execute_reply.started":"2024-04-10T16:20:26.611374Z","shell.execute_reply":"2024-04-10T16:20:26.614662Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Add documents","metadata":{}},{"cell_type":"markdown","source":"### Let's download the sample dataset and deserialize the document.","metadata":{}},{"cell_type":"code","source":"url = \"https://raw.githubusercontent.com/elastic/elasticsearch-labs/main/datasets/workplace-documents.json\"\n\nresponse = urlopen(url)\n\nworkplace_docs = json.loads(response.read())","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:20:28.345171Z","iopub.execute_input":"2024-04-10T16:20:28.345824Z","iopub.status.idle":"2024-04-10T16:20:28.484513Z","shell.execute_reply.started":"2024-04-10T16:20:28.345779Z","shell.execute_reply":"2024-04-10T16:20:28.483612Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def get_response_from_endpoint(url, headers=None):\n    try:\n        response = requests.get(url, headers=headers)\n        # Check if the request was successful (status code 200)\n        if response.status_code == 200:\n            return response.json()  # Return the JSON response\n        else:\n            return None  # Return None if request was not successful\n    except requests.exceptions.RequestException as e:\n        print(\"Error:\", e)\n        return None","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:20:29.382275Z","iopub.execute_input":"2024-04-10T16:20:29.383095Z","iopub.status.idle":"2024-04-10T16:20:29.388557Z","shell.execute_reply.started":"2024-04-10T16:20:29.383063Z","shell.execute_reply":"2024-04-10T16:20:29.387530Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"API_KEY = \"1da6d9512ad00fc394bd04234bc7358dc9b85d96fa0c56281f710dc9abcef7e5\"\n\ncustom_headers = {\n    \"Authorization\": f\"Token token={API_KEY}\",\n    \"Content Type\": \"application/vnd.api+json\"\n}","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:20:30.134076Z","iopub.execute_input":"2024-04-10T16:20:30.134731Z","iopub.status.idle":"2024-04-10T16:20:30.139269Z","shell.execute_reply.started":"2024-04-10T16:20:30.134700Z","shell.execute_reply":"2024-04-10T16:20:30.138246Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def extract_review_info(review):\n    # Extracting attributes\n    attributes = review.get(\"attributes\", {})\n    product_name = attributes.get(\"product_name\", \"\")\n    star_rating = attributes.get(\"star_rating\", \"\")\n    title = attributes.get(\"title\", \"\")\n    user_name = attributes.get(\"user_name\", \"\")\n    submitted_at = attributes.get(\"submitted_at\", \"\")\n    review_source = attributes.get(\"review_source\", \"\")\n    votes_up = attributes.get(\"votes_up\", \"\")\n    votes_down = attributes.get(\"votes_down\", \"\")\n    country_name = attributes.get(\"country_name\", \"\")\n    \n    # Extracting comment answers\n    comment_answers = attributes.get(\"comment_answers\", {})\n    love = comment_answers.get(\"love\", {}).get(\"value\", \"\")\n    hate = comment_answers.get(\"hate\", {}).get(\"value\", \"\")\n    benefits = comment_answers.get(\"benefits\", {}).get(\"value\", \"\")\n    recommendations = comment_answers.get(\"recommendations\", {}).get(\"value\", \"\")\n    \n    # Extracting secondary answers\n    secondary_answers = attributes.get(\"secondary_answers\", {})\n    meets_requirements = secondary_answers.get(\"meets_requirements\", {}).get(\"value\", \"\")\n    ease_of_use = secondary_answers.get(\"ease_of_use\", {}).get(\"value\", \"\")\n    quality_of_support = secondary_answers.get(\"quality_of_support\", {}).get(\"value\", \"\")\n    ease_of_setup = secondary_answers.get(\"ease_of_setup\", {}).get(\"value\", \"\")\n    ease_of_admin = secondary_answers.get(\"ease_of_admin\", {}).get(\"value\", \"\")\n    ease_of_doing_business_with = secondary_answers.get(\"ease_of_doing_business_with\", {}).get(\"value\", \"\")\n    \n    # Constructing content\n    content = f\"\"\"\n    Product Name: {product_name}\n    Star Rating: {star_rating}\n    Title: {title}\n    User Name: {user_name}\n    Submitted At: {submitted_at}\n    Review Source: {review_source}\n    Votes Up: {votes_up}\n    Votes Down: {votes_down}\n    Country Name: {country_name}\n    \n    Love: {love}\n    Hate: {hate}\n    Benefits: {benefits}\n    Recommendations: {recommendations}\n    \n    Secondary Answers:\n    Meets Requirements: {meets_requirements}\n    Ease of Use: {ease_of_use}\n    Quality of Support: {quality_of_support}\n    Ease of Setup: {ease_of_setup}\n    Ease of Admin: {ease_of_admin}\n    Ease of Doing Business With: {ease_of_doing_business_with}\n    \"\"\"\n    \n    # Extracting relationships metadata\n    relationships = review.get(\"relationships\", {})\n    product_link = relationships.get(\"product\", {}).get(\"links\", {}).get(\"self\", \"\")\n    questions_link = relationships.get(\"questions\", {}).get(\"links\", {}).get(\"self\", \"\")\n    answers_link = relationships.get(\"answers\", {}).get(\"links\", {}).get(\"self\", \"\")\n    \n    # Constructing metadata\n    metadata = {\n        \"product_link\": product_link,\n        \"questions_link\": questions_link,\n        \"answers_link\": answers_link\n    }\n    \n    return content.strip(), metadata","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:20:30.915077Z","iopub.execute_input":"2024-04-10T16:20:30.915703Z","iopub.status.idle":"2024-04-10T16:20:30.929013Z","shell.execute_reply.started":"2024-04-10T16:20:30.915673Z","shell.execute_reply":"2024-04-10T16:20:30.928118Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Split Documents into Passages","metadata":{}},{"cell_type":"code","source":"metadata = []\ncontent = []\n\n\"\"\"for doc in workplace_docs:\n    content.append(doc[\"content\"])\n    metadata.append(\n        {\n            \"name\": doc[\"name\"],\n            \"summary\": doc[\"summary\"],\n            \"rolePermissions\": doc[\"rolePermissions\"],\n        }\n    )\"\"\"\nfor i in range(77):\n    url=f\"https://data.g2.com/api/v1/survey-responses?page%5Bnumber%5D={i+1}&page%5Bsize%5D=10\"\n    response_data=get_response_from_endpoint(url,custom_headers)\n    temp_list=[extract_review_info(review) for review in response_data[\"data\"]]\n    content.extend([review_content for review_content,_ in temp_list])\n    metadata.extend([review_metadata for _,review_metadata in temp_list])","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:20:32.063349Z","iopub.execute_input":"2024-04-10T16:20:32.063988Z","iopub.status.idle":"2024-04-10T16:20:56.099774Z","shell.execute_reply.started":"2024-04-10T16:20:32.063953Z","shell.execute_reply":"2024-04-10T16:20:56.098875Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"text_splitter = CharacterTextSplitter(chunk_size=50, chunk_overlap=0)\ndocs = text_splitter.create_documents(content, metadatas=metadata)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:20:56.101925Z","iopub.execute_input":"2024-04-10T16:20:56.102346Z","iopub.status.idle":"2024-04-10T16:20:56.141951Z","shell.execute_reply.started":"2024-04-10T16:20:56.102310Z","shell.execute_reply":"2024-04-10T16:20:56.141018Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Index Documents into Elasticsearch using ELSER\n\nBefore we begin indexing, ensure you have [downloaded and deployed the ELSER model](https://www.elastic.co/guide/en/machine-learning/current/ml-nlp-elser.html#download-deploy-elser) in your deployment and is running on the ML node.","metadata":{}},{"cell_type":"code","source":"es = ElasticsearchStore.from_documents(\n    docs,\n    es_cloud_id=ELASTIC_CLOUD_ID,\n    es_api_key=ELASTIC_API_KEY,\n    index_name=elastic_index_name,\n    strategy=ElasticsearchStore.SparseVectorRetrievalStrategy(\n        model_id=\".elser_model_2\"\n    ),\n    request_timeout=180\n    ,timeout=180\n)\n\nes","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:20:56.143130Z","iopub.execute_input":"2024-04-10T16:20:56.143448Z","iopub.status.idle":"2024-04-10T16:21:00.219219Z","shell.execute_reply.started":"2024-04-10T16:20:56.143421Z","shell.execute_reply":"2024-04-10T16:21:00.217790Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<langchain_community.vectorstores.elasticsearch.ElasticsearchStore at 0x7c95a0109c90>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Hugging Face login","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()#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","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:21:00.222509Z","iopub.execute_input":"2024-04-10T16:21:00.222911Z","iopub.status.idle":"2024-04-10T16:21:00.254675Z","shell.execute_reply.started":"2024-04-10T16:21:00.222871Z","shell.execute_reply":"2024-04-10T16:21:00.252927Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c54ccc549b54c0aafd2f121fb06332a"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Initialize the tokenizer with the model (`google/gemma-2b-it`)","metadata":{}},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2b-it\",device_map=\"auto\")\ntokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2b-it\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:21:00.255711Z","iopub.execute_input":"2024-04-10T16:21:00.256144Z","iopub.status.idle":"2024-04-10T16:21:08.351744Z","shell.execute_reply.started":"2024-04-10T16:21:00.256110Z","shell.execute_reply":"2024-04-10T16:21:08.350688Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52f1d605a7f64ef0960a86f76cbc7951"}},"metadata":{}}]},{"cell_type":"code","source":"#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#model = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:21:08.352916Z","iopub.execute_input":"2024-04-10T16:21:08.353223Z","iopub.status.idle":"2024-04-10T16:21:08.357457Z","shell.execute_reply.started":"2024-04-10T16:21:08.353197Z","shell.execute_reply":"2024-04-10T16:21:08.356491Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"#model = DataParallel(model)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:21:08.358485Z","iopub.execute_input":"2024-04-10T16:21:08.358772Z","iopub.status.idle":"2024-04-10T16:21:08.368744Z","shell.execute_reply.started":"2024-04-10T16:21:08.358748Z","shell.execute_reply":"2024-04-10T16:21:08.367877Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Create a `text-generation` pipeline and initialize with LLM","metadata":{}},{"cell_type":"code","source":"pipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=1024,\n)\n\nllm = HuggingFacePipeline(\n    pipeline=pipe,\n    model_kwargs={\"temperature\": 0.7},\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:21:08.369867Z","iopub.execute_input":"2024-04-10T16:21:08.370222Z","iopub.status.idle":"2024-04-10T16:21:08.448974Z","shell.execute_reply.started":"2024-04-10T16:21:08.370191Z","shell.execute_reply":"2024-04-10T16:21:08.448082Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Format Docs","metadata":{}},{"cell_type":"code","source":"def format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:21:08.450159Z","iopub.execute_input":"2024-04-10T16:21:08.450451Z","iopub.status.idle":"2024-04-10T16:21:08.460307Z","shell.execute_reply.started":"2024-04-10T16:21:08.450427Z","shell.execute_reply":"2024-04-10T16:21:08.459429Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Create a chain using Prompt template","metadata":{}},{"cell_type":"code","source":"retriever = es.as_retriever(search_kwargs={\"k\": 5})\n\ntemplate = \"\"\"Answer the question based only on the following context:\\n\n\n{context}\n\nQuestion: {question}\n\"\"\"\n\nprompt = ChatPromptTemplate.from_template(template)\n\nchain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:21:08.462774Z","iopub.execute_input":"2024-04-10T16:21:08.463086Z","iopub.status.idle":"2024-04-10T16:21:08.472457Z","shell.execute_reply.started":"2024-04-10T16:21:08.463035Z","shell.execute_reply":"2024-04-10T16:21:08.471587Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Ask question","metadata":{}},{"cell_type":"code","source":"chain.invoke(\"Explain more about G2 reviews\")","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:22:51.134945Z","iopub.execute_input":"2024-04-10T16:22:51.135874Z","iopub.status.idle":"2024-04-10T16:22:57.573066Z","shell.execute_reply.started":"2024-04-10T16:22:51.135830Z","shell.execute_reply":"2024-04-10T16:22:57.572098Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"'Human: Answer the question based only on the following context:\\n\\n\\nProduct Name: G2 Marketing Solutions\\n    Star Rating: 5.0\\n    Title: G2 is the most important tool in my tech stack\\n    User Name: Jake Sotir\\n    Submitted At: 2022-12-02T14:59:05.999-06:00\\n    Review Source: G2 Gives Campaign. This reviewer was offered a donation to a charitable cause in their name as thanks for completing this review.\\n    Votes Up: 0\\n    Votes Down: 0\\n    Country Name: United States\\n    \\n    Love: I use G2 to collect customer reviews. As a Customer Marketer, that stuff is like pure gold to me. Both from a product feedback standpoint and from a market perception standpoint, nothing is more valuable than a constant influx of customer reviews.\\n    Hate: I occasionally wish that there was less of a desire to game the system, which is relatively easy to do with G2. Sometimes I feel like our position on the grid and within G2\\'s algorithm isn\\'t a true representation of our market share and perception, and that can be frustrating to overcome. That said, the algorithm is what it is, and it\\'s all about maximizing the potential of your profile.\\n    Benefits: G2 gives us amazing insight into direct customer feedback and helping us prove our value to the market.\\n    Recommendations: \\n    \\n    Secondary Answers:\\n    Meets Requirements: 7.0\\n    Ease of Use: 7.0\\n    Quality of Support: 7.0\\n    Ease of Setup: 7.0\\n    Ease of Admin: 7.0\\n    Ease of Doing Business With: 6.0\\n\\nProduct Name: G2 Marketing Solutions\\n    Star Rating: 5.0\\n    Title: G2 is the most important tool in my tech stack\\n    User Name: Jake Sotir\\n    Submitted At: 2022-12-02T14:59:05.999-06:00\\n    Review Source: G2 Gives Campaign. This reviewer was offered a donation to a charitable cause in their name as thanks for completing this review.\\n    Votes Up: 0\\n    Votes Down: 0\\n    Country Name: United States\\n    \\n    Love: I use G2 to collect customer reviews. As a Customer Marketer, that stuff is like pure gold to me. Both from a product feedback standpoint and from a market perception standpoint, nothing is more valuable than a constant influx of customer reviews.\\n    Hate: I occasionally wish that there was less of a desire to game the system, which is relatively easy to do with G2. Sometimes I feel like our position on the grid and within G2\\'s algorithm isn\\'t a true representation of our market share and perception, and that can be frustrating to overcome. That said, the algorithm is what it is, and it\\'s all about maximizing the potential of your profile.\\n    Benefits: G2 gives us amazing insight into direct customer feedback and helping us prove our value to the market.\\n    Recommendations: \\n    \\n    Secondary Answers:\\n    Meets Requirements: 7.0\\n    Ease of Use: 7.0\\n    Quality of Support: 7.0\\n    Ease of Setup: 7.0\\n    Ease of Admin: 7.0\\n    Ease of Doing Business With: 6.0\\n\\nProduct Name: G2 Marketing Solutions\\n    Star Rating: 5.0\\n    Title: G2 is the most important tool in my tech stack\\n    User Name: Jake Sotir\\n    Submitted At: 2022-12-02T14:59:05.999-06:00\\n    Review Source: G2 Gives Campaign. This reviewer was offered a donation to a charitable cause in their name as thanks for completing this review.\\n    Votes Up: 0\\n    Votes Down: 0\\n    Country Name: United States\\n    \\n    Love: I use G2 to collect customer reviews. As a Customer Marketer, that stuff is like pure gold to me. Both from a product feedback standpoint and from a market perception standpoint, nothing is more valuable than a constant influx of customer reviews.\\n    Hate: I occasionally wish that there was less of a desire to game the system, which is relatively easy to do with G2. Sometimes I feel like our position on the grid and within G2\\'s algorithm isn\\'t a true representation of our market share and perception, and that can be frustrating to overcome. That said, the algorithm is what it is, and it\\'s all about maximizing the potential of your profile.\\n    Benefits: G2 gives us amazing insight into direct customer feedback and helping us prove our value to the market.\\n    Recommendations: \\n    \\n    Secondary Answers:\\n    Meets Requirements: 7.0\\n    Ease of Use: 7.0\\n    Quality of Support: 7.0\\n    Ease of Setup: 7.0\\n    Ease of Admin: 7.0\\n    Ease of Doing Business With: 6.0\\n\\nProduct Name: G2 Marketing Solutions\\n    Star Rating: 4.0\\n    Title: Good early traction, then fall-off\\n    User Name: Verified User in Computer Software\\n    Submitted At: 2023-12-06T16:00:17.805-06:00\\n    Review Source: G2 Gives Campaign. This reviewer was offered a donation to a charitable cause in their name as thanks for completing this review.\\n    Votes Up: 0\\n    Votes Down: 0\\n    Country Name: None\\n    \\n    Love: Great personal account support. Our rep meets with us regularly and tries to do all she can to help us get the most out of the G2 system.\\n    Hate: G2 itself is extremely janky. We had to write up & justify the category that we belong in because G2 didn\\'t understand our industry. We needed to explain why we should or shouldn\\'t be tucked up underneath other categories. We needed to explain, in long-form, why certain companies they identified as our competitors should not even *be* in the category they threw them into.\\r\\n\\r\\nTalking with Monty, he literally could not even recognize our product category and instead provided to me pages of unrelated market segments. When I gave him the exact page in G2 that I was referring to it said \"I don\\'t have access to live G2 database but I rely on set of structured database information which I currently lack for [my company\\'s category].\"\\r\\n\\r\\nWhile we had initial traction in getting reviews once we signed the contract, that dried up quickly (after 1-2 months) and then we haven\\'t gotten *any* reviews in the past half-year.\\r\\n\\r\\nI wish I got sentiment analytics on the page even if someone *didn\\'t* leave a review. I wish there was a way to know how many users were \"watching us\" or whether they had a positive brand sentiment. I can see pageviews, but I wish I could tell if folks were \"subscribed\" to our brand. So we could push updated information to those who had more than passing interest.\\n    Benefits: We want a public \"score\" for our product and have that appear in a place where our competitors also appear. We want to at least be given our fair share of voice. So far G2 has allowed us to be findable in a head-to-head comparison site.\\n    Recommendations: \\n    \\n    Secondary Answers:\\n    Meets Requirements: \\n    Ease of Use: \\n    Quality of Support: \\n    Ease of Setup: \\n    Ease of Admin: \\n    Ease of Doing Business With:\\n\\nProduct Name: G2 Marketing Solutions\\n    Star Rating: 4.0\\n    Title: Good early traction, then fall-off\\n    User Name: Verified User in Computer Software\\n    Submitted At: 2023-12-06T16:00:17.805-06:00\\n    Review Source: G2 Gives Campaign. This reviewer was offered a donation to a charitable cause in their name as thanks for completing this review.\\n    Votes Up: 0\\n    Votes Down: 0\\n    Country Name: None\\n    \\n    Love: Great personal account support. Our rep meets with us regularly and tries to do all she can to help us get the most out of the G2 system.\\n    Hate: G2 itself is extremely janky. We had to write up & justify the category that we belong in because G2 didn\\'t understand our industry. We needed to explain why we should or shouldn\\'t be tucked up underneath other categories. We needed to explain, in long-form, why certain companies they identified as our competitors should not even *be* in the category they threw them into.\\r\\n\\r\\nTalking with Monty, he literally could not even recognize our product category and instead provided to me pages of unrelated market segments. When I gave him the exact page in G2 that I was referring to it said \"I don\\'t have access to live G2 database but I rely on set of structured database information which I currently lack for [my company\\'s category].\"\\r\\n\\r\\nWhile we had initial traction in getting reviews once we signed the contract, that dried up quickly (after 1-2 months) and then we haven\\'t gotten *any* reviews in the past half-year.\\r\\n\\r\\nI wish I got sentiment analytics on the page even if someone *didn\\'t* leave a review. I wish there was a way to know how many users were \"watching us\" or whether they had a positive brand sentiment. I can see pageviews, but I wish I could tell if folks were \"subscribed\" to our brand. So we could push updated information to those who had more than passing interest.\\n    Benefits: We want a public \"score\" for our product and have that appear in a place where our competitors also appear. We want to at least be given our fair share of voice. So far G2 has allowed us to be findable in a head-to-head comparison site.\\n    Recommendations: \\n    \\n    Secondary Answers:\\n    Meets Requirements: \\n    Ease of Use: \\n    Quality of Support: \\n    Ease of Setup: \\n    Ease of Admin: \\n    Ease of Doing Business With:\\n\\nQuestion: Explain more about G2 reviews\\nAnswer: G2 reviews are a way for customers to give feedback on their product. G2 uses these reviews to improve their product and to make it more appealing to customers. Reviews are also a way for customers to share their thoughts with other customers.'"},"metadata":{}}]},{"cell_type":"code","source":"device_ids = [0, 1]  # Assuming you want to clear memory of GPU 0 and GPU 1\ndevices = [torch.device(f\"cuda:{gpu_id}\") for gpu_id in device_ids]\n\n# Clear memory for each GPU\nfor device in devices:\n    with torch.cuda.device(device):\n        gc.collect()\n        torch.cuda.empty_cache()\n\nprint(\"Memory cleared for GPUs:\", device_ids)","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:22:32.564474Z","iopub.execute_input":"2024-04-10T16:22:32.565185Z","iopub.status.idle":"2024-04-10T16:22:33.371170Z","shell.execute_reply.started":"2024-04-10T16:22:32.565152Z","shell.execute_reply":"2024-04-10T16:22:33.370127Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Memory cleared for GPUs: [0, 1]\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:22:43.254985Z","iopub.execute_input":"2024-04-10T16:22:43.255822Z","iopub.status.idle":"2024-04-10T16:22:44.379154Z","shell.execute_reply.started":"2024-04-10T16:22:43.255784Z","shell.execute_reply":"2024-04-10T16:22:44.377941Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Wed Apr 10 16:22:44 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n| N/A   66C    P0              30W /  70W |   5931MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n| N/A   68C    P0              31W /  70W |   3931MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"#ray.init()","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:24:14.385386Z","iopub.execute_input":"2024-04-10T16:24:14.385774Z","iopub.status.idle":"2024-04-10T16:24:14.390286Z","shell.execute_reply.started":"2024-04-10T16:24:14.385745Z","shell.execute_reply":"2024-04-10T16:24:14.389245Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"\n\"\"\"@ray.remote(num_gpus=2)\nclass RemoteRetriever:\n    def __init__(self):\n        self.retriever = retriever\n\n    def retrieve(self, input_query):\n        return self.retriever(input_query)\n\n@ray.remote(num_gpus=2)\nclass RemoteLLM:\n    def __init__(self):\n        self.llm = llm\n\n    def generate_text(self, input_text):\n        return self.llm(input_text)\n\n# Define the pipeline\nchain = (\n    {\"context\": RemoteRetriever.remote() | format_docs, \"question\": RunnablePassthrough()}\n    | prompt\n    | RemoteLLM.remote()\n    | StrOutputParser()\n)\n\n# Example usage of the pipeline\ninput_query = \"EXplain about g2\"\noutput = ray.get(chain.run(input_query))\nprint(output)\n\n# Shutdown Ray\nray.shutdown()\"\"\"","metadata":{"execution":{"iopub.status.busy":"2024-04-10T16:24:16.113119Z","iopub.execute_input":"2024-04-10T16:24:16.114003Z","iopub.status.idle":"2024-04-10T16:24:16.120591Z","shell.execute_reply.started":"2024-04-10T16:24:16.113971Z","shell.execute_reply":"2024-04-10T16:24:16.119625Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'@ray.remote(num_gpus=2)\\nclass RemoteRetriever:\\n    def __init__(self):\\n        self.retriever = retriever\\n\\n    def retrieve(self, input_query):\\n        return self.retriever(input_query)\\n\\n@ray.remote(num_gpus=2)\\nclass RemoteLLM:\\n    def __init__(self):\\n        self.llm = llm\\n\\n    def generate_text(self, input_text):\\n        return self.llm(input_text)\\n\\n# Define the pipeline\\nchain = (\\n    {\"context\": RemoteRetriever.remote() | format_docs, \"question\": RunnablePassthrough()}\\n    | prompt\\n    | RemoteLLM.remote()\\n    | StrOutputParser()\\n)\\n\\n# Example usage of the pipeline\\ninput_query = \"EXplain about g2\"\\noutput = ray.get(chain.run(input_query))\\nprint(output)\\n\\n# Shutdown Ray\\nray.shutdown()'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}